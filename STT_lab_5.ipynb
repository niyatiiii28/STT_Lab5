{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4a60640ee7d430eb88a0ac111970263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_955c919011924c8ca3f4173f700864ec",
              "IPY_MODEL_ab53d7138f0c442398c5f28844e8af45",
              "IPY_MODEL_e0e630cbfa6c4d1a96af82c394a79371"
            ],
            "layout": "IPY_MODEL_f7900d740a8747fabbc8e01bcd995699"
          }
        },
        "955c919011924c8ca3f4173f700864ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5941c1fccbb349a987c645b7a04a28ae",
            "placeholder": "​",
            "style": "IPY_MODEL_e39f563e3d7f4224a0a871277dd2ed96",
            "value": "config.json: 100%"
          }
        },
        "ab53d7138f0c442398c5f28844e8af45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8eb12cf7d14b589acebb9f940b59b8",
            "max": 69556,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70f6455952dc4e5697c38feaad3ccb5f",
            "value": 69556
          }
        },
        "e0e630cbfa6c4d1a96af82c394a79371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35ae5079260d4b0d8236b3f8d9550702",
            "placeholder": "​",
            "style": "IPY_MODEL_9604a3d8c18d439597b34eab2cd571d7",
            "value": " 69.6k/69.6k [00:00&lt;00:00, 4.45MB/s]"
          }
        },
        "f7900d740a8747fabbc8e01bcd995699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5941c1fccbb349a987c645b7a04a28ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39f563e3d7f4224a0a871277dd2ed96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa8eb12cf7d14b589acebb9f940b59b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f6455952dc4e5697c38feaad3ccb5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35ae5079260d4b0d8236b3f8d9550702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9604a3d8c18d439597b34eab2cd571d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d631d82317c248028ba3e65c56812626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1df7178712e4b169fa6cd16d9425c0e",
              "IPY_MODEL_a7d071fa429148209bedfcc369100f8d",
              "IPY_MODEL_6b3d845db5984ae9813ebdb0444ea998"
            ],
            "layout": "IPY_MODEL_fa064b7e6128425ab4398a07c0ffa4e5"
          }
        },
        "f1df7178712e4b169fa6cd16d9425c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808b60b052a34380ac9f88039b950a81",
            "placeholder": "​",
            "style": "IPY_MODEL_0da3a921e3b54d94826b7e55a78adde1",
            "value": "model.safetensors: 100%"
          }
        },
        "a7d071fa429148209bedfcc369100f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f3205ea914a451bbbf98e310c58c77c",
            "max": 102482854,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_752b0bb9d20f4cf0a2ef2d57cff650a2",
            "value": 102482854
          }
        },
        "6b3d845db5984ae9813ebdb0444ea998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a71957779c84c78ae9ee0bad1f61da9",
            "placeholder": "​",
            "style": "IPY_MODEL_46c0887919bd4f5b8b28a2df09ee2c52",
            "value": " 102M/102M [00:00&lt;00:00, 234MB/s]"
          }
        },
        "fa064b7e6128425ab4398a07c0ffa4e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808b60b052a34380ac9f88039b950a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da3a921e3b54d94826b7e55a78adde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f3205ea914a451bbbf98e310c58c77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752b0bb9d20f4cf0a2ef2d57cff650a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a71957779c84c78ae9ee0bad1f61da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c0887919bd4f5b8b28a2df09ee2c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fb682fcd73b42c8b52a501494799c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6828e3b1945e45beb5a25202ae48b77f",
              "IPY_MODEL_ee162c6cb23642c281cae8dea30a9af9",
              "IPY_MODEL_55f1dd928854412189a30210c01aa6f2"
            ],
            "layout": "IPY_MODEL_372d6b7d38834305bc1337c3e7c81742"
          }
        },
        "6828e3b1945e45beb5a25202ae48b77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c86c15432d4715a9d9a029a8eef42c",
            "placeholder": "​",
            "style": "IPY_MODEL_11376694ce80412b8e3ccdac17e81bcf",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "ee162c6cb23642c281cae8dea30a9af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a151fb370b49688972791ed3e24afd",
            "max": 266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88f84c16b42447ed9ea00efbd9a762ee",
            "value": 266
          }
        },
        "55f1dd928854412189a30210c01aa6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af71894449454de89bb0e2c3bba27ddf",
            "placeholder": "​",
            "style": "IPY_MODEL_3551398974f24c06953616cb292a0192",
            "value": " 266/266 [00:00&lt;00:00, 21.0kB/s]"
          }
        },
        "372d6b7d38834305bc1337c3e7c81742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c86c15432d4715a9d9a029a8eef42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11376694ce80412b8e3ccdac17e81bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16a151fb370b49688972791ed3e24afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88f84c16b42447ed9ea00efbd9a762ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af71894449454de89bb0e2c3bba27ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3551398974f24c06953616cb292a0192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install augly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OKEmXDavaF8U",
        "outputId": "76b7349f-e342-412d-fa31-b4898f862145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting augly\n",
            "  Downloading augly-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting iopath>=0.1.8 (from augly)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic>=0.4.22 (from augly)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: regex>=2021.4.4 in /usr/local/lib/python3.11/dist-packages (from augly) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.8->augly) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.8->augly) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.8->augly)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading augly-1.0.0-py3-none-any.whl (24.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: iopath\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=a445aaedfa06388d9f26acd269978e9023835cf5ebbb5925f29ffe99d8a91911\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built iopath\n",
            "Installing collected packages: python-magic, portalocker, iopath, augly\n",
            "Successfully installed augly-1.0.0 iopath-0.1.10 portalocker-3.1.1 python-magic-0.4.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade augly pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ9Ggz8-tAU3",
        "outputId": "635be98b-7037-4525-f7d2-7cdcbb47605a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: augly in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: iopath>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from augly) (0.1.10)\n",
            "Requirement already satisfied: python-magic>=0.4.22 in /usr/local/lib/python3.11/dist-packages (from augly) (0.4.27)\n",
            "Requirement already satisfied: regex>=2021.4.4 in /usr/local/lib/python3.11/dist-packages (from augly) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.8->augly) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.8->augly) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.8->augly) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/test.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "glA-Cl1jnRIX",
        "outputId": "f44fb377-3160-4999-ee1d-bf504a1b747d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip\n",
            "   creating: cats/\n",
            "  inflating: cats/cat_190.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_190.jpg  \n",
            "  inflating: cats/cat_147.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_147.jpg  \n",
            "  inflating: cats/cat_542.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_542.jpg  \n",
            "  inflating: cats/cat_595.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_595.jpg  \n",
            "  inflating: cats/cat_422.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_422.jpg  \n",
            "  inflating: cats/cat_583.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_583.jpg  \n",
            "  inflating: cats/cat_384.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_384.jpg  \n",
            "  inflating: cats/cat_586.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_586.jpg  \n",
            "  inflating: cats/cat_545.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_545.jpg  \n",
            "  inflating: cats/cat_223.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_223.jpg  \n",
            "  inflating: cats/cat_551.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_551.jpg  \n",
            "  inflating: cats/cat_587.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_587.jpg  \n",
            "  inflating: cats/cat_140.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_140.jpg  \n",
            "  inflating: cats/cat_342.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_342.jpg  \n",
            "  inflating: cats/cat_430.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_430.jpg  \n",
            "  inflating: cats/cat_418.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_418.jpg  \n",
            "  inflating: cats/cat_395.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_395.jpg  \n",
            "  inflating: cats/cat_156.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_156.jpg  \n",
            "  inflating: cats/cat_585.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_585.jpg  \n",
            "  inflating: cats/cat_234.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_234.jpg  \n",
            "  inflating: cats/cat_355.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_355.jpg  \n",
            "  inflating: cats/cat_433.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_433.jpg  \n",
            "  inflating: cats/cat_341.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_341.jpg  \n",
            "  inflating: cats/cat_332.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_332.jpg  \n",
            "  inflating: cats/cat_468.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_468.jpg  \n",
            "  inflating: cats/cat_124.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_124.jpg  \n",
            "  inflating: cats/cat_118.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_118.jpg  \n",
            "  inflating: cats/cat_520.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_520.jpg  \n",
            "  inflating: cats/cat_290.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_290.jpg  \n",
            "  inflating: cats/cat_119.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_119.jpg  \n",
            "  inflating: cats/cat_88.jpg         \n",
            "  inflating: __MACOSX/cats/._cat_88.jpg  \n",
            "  inflating: cats/cat_496.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_496.jpg  \n",
            "  inflating: cats/cat_523.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_523.jpg  \n",
            "  inflating: cats/cat_251.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_251.jpg  \n",
            "  inflating: cats/cat_279.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_279.jpg  \n",
            "  inflating: cats/cat_244.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_244.jpg  \n",
            "  inflating: cats/cat_60.jpg         \n",
            "  inflating: __MACOSX/cats/._cat_60.jpg  \n",
            "  inflating: cats/cat_446.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_446.jpg  \n",
            "  inflating: cats/cat_268.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_268.jpg  \n",
            "  inflating: cats/cat_255.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_255.jpg  \n",
            "  inflating: cats/cat_109.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_109.jpg  \n",
            "  inflating: cats/cat_525.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_525.jpg  \n",
            "  inflating: cats/cat_281.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_281.jpg  \n",
            "  inflating: cats/cat_94.jpg         \n",
            "  inflating: __MACOSX/cats/._cat_94.jpg  \n",
            "  inflating: cats/cat_313.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_313.jpg  \n",
            "  inflating: cats/cat_1.jpg          \n",
            "  inflating: __MACOSX/cats/._cat_1.jpg  \n",
            "  inflating: cats/cat_528.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_528.jpg  \n",
            "  inflating: cats/cat_306.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_306.jpg  \n",
            "  inflating: cats/cat_56.jpg         \n",
            "  inflating: __MACOSX/cats/._cat_56.jpg  \n",
            "  inflating: cats/cat_106.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_106.jpg  \n",
            "  inflating: cats/cat_113.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_113.jpg  \n",
            "  inflating: cats/cat_96.jpg         \n",
            "  inflating: __MACOSX/cats/._cat_96.jpg  \n",
            "  inflating: cats/cat_473.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_473.jpg  \n",
            "  inflating: cats/cat_116.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_116.jpg  \n",
            "  inflating: cats/cat_464.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_464.jpg  \n",
            "  inflating: cats/cat_114.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_114.jpg  \n",
            "  inflating: cats/cat_538.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_538.jpg  \n",
            "  inflating: cats/cat_504.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_504.jpg  \n",
            "  inflating: cats/cat_5.jpg          \n",
            "  inflating: __MACOSX/cats/._cat_5.jpg  \n",
            "  inflating: cats/cat_358.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_358.jpg  \n",
            "  inflating: cats/cat_417.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_417.jpg  \n",
            "  inflating: cats/cat_371.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_371.jpg  \n",
            "  inflating: cats/cat_575.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_575.jpg  \n",
            "  inflating: cats/cat_574.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_574.jpg  \n",
            "  inflating: cats/cat_158.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_158.jpg  \n",
            "  inflating: cats/cat_564.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_564.jpg  \n",
            "  inflating: cats/cat_203.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_203.jpg  \n",
            "  inflating: cats/cat_375.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_375.jpg  \n",
            "  inflating: cats/cat_162.jpg        \n",
            "  inflating: __MACOSX/cats/._cat_162.jpg  \n",
            "  inflating: cats/cat_18.jpg         \n",
            "  inflating: __MACOSX/cats/._cat_18.jpg  \n",
            "   creating: dogs/\n",
            "  inflating: dogs/dog_147.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_147.jpg  \n",
            "  inflating: dogs/dog_219.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_219.jpg  \n",
            "  inflating: dogs/dog_191.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_191.jpg  \n",
            "  inflating: dogs/dog_344.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_344.jpg  \n",
            "  inflating: dogs/dog_150.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_150.jpg  \n",
            "  inflating: dogs/dog_227.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_227.jpg  \n",
            "  inflating: dogs/dog_421.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_421.jpg  \n",
            "  inflating: dogs/dog_380.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_380.jpg  \n",
            "  inflating: dogs/dog_155.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_155.jpg  \n",
            "  inflating: dogs/dog_141.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_141.jpg  \n",
            "  inflating: dogs/dog_196.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_196.jpg  \n",
            "  inflating: dogs/dog_551.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_551.jpg  \n",
            "  inflating: dogs/dog_237.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_237.jpg  \n",
            "  inflating: dogs/dog_236.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_236.jpg  \n",
            "  inflating: dogs/dog_197.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_197.jpg  \n",
            "  inflating: dogs/dog_168.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_168.jpg  \n",
            "  inflating: dogs/dog_28.jpg         \n",
            "  inflating: __MACOSX/dogs/._dog_28.jpg  \n",
            "  inflating: dogs/dog_354.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_354.jpg  \n",
            "  inflating: dogs/dog_142.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_142.jpg  \n",
            "  inflating: dogs/dog_181.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_181.jpg  \n",
            "  inflating: dogs/dog_194.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_194.jpg  \n",
            "  inflating: dogs/dog_369.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_369.jpg  \n",
            "  inflating: dogs/dog_355.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_355.jpg  \n",
            "  inflating: dogs/dog_124.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_124.jpg  \n",
            "  inflating: dogs/dog_130.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_130.jpg  \n",
            "  inflating: dogs/dog_534.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_534.jpg  \n",
            "  inflating: dogs/dog_520.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_520.jpg  \n",
            "  inflating: dogs/dog_521.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_521.jpg  \n",
            "  inflating: dogs/dog_482.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_482.jpg  \n",
            "  inflating: dogs/dog_59.jpg         \n",
            "  inflating: __MACOSX/dogs/._dog_59.jpg  \n",
            "  inflating: dogs/dog_327.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_327.jpg  \n",
            "  inflating: dogs/dog_443.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_443.jpg  \n",
            "  inflating: dogs/dog_536.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_536.jpg  \n",
            "  inflating: dogs/dog_244.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_244.jpg  \n",
            "  inflating: dogs/dog_522.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_522.jpg  \n",
            "  inflating: dogs/dog_442.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_442.jpg  \n",
            "  inflating: dogs/dog_89.jpg         \n",
            "  inflating: __MACOSX/dogs/._dog_89.jpg  \n",
            "  inflating: dogs/dog_240.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_240.jpg  \n",
            "  inflating: dogs/dog_283.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_283.jpg  \n",
            "  inflating: dogs/dog_123.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_123.jpg  \n",
            "  inflating: dogs/dog_75.jpg         \n",
            "  inflating: __MACOSX/dogs/._dog_75.jpg  \n",
            "  inflating: dogs/dog_519.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_519.jpg  \n",
            "  inflating: dogs/dog_518.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_518.jpg  \n",
            "  inflating: dogs/dog_461.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_461.jpg  \n",
            "  inflating: dogs/dog_313.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_313.jpg  \n",
            "  inflating: dogs/dog_528.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_528.jpg  \n",
            "  inflating: dogs/dog_44.jpg         \n",
            "  inflating: __MACOSX/dogs/._dog_44.jpg  \n",
            "  inflating: dogs/dog_476.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_476.jpg  \n",
            "  inflating: dogs/dog_462.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_462.jpg  \n",
            "  inflating: dogs/dog_258.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_258.jpg  \n",
            "  inflating: dogs/dog_517.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_517.jpg  \n",
            "  inflating: dogs/dog_43.jpg         \n",
            "  inflating: __MACOSX/dogs/._dog_43.jpg  \n",
            "  inflating: dogs/dog_472.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_472.jpg  \n",
            "  inflating: dogs/dog_464.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_464.jpg  \n",
            "  inflating: dogs/dog_302.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_302.jpg  \n",
            "  inflating: dogs/dog_68.jpg         \n",
            "  inflating: __MACOSX/dogs/._dog_68.jpg  \n",
            "  inflating: dogs/dog_114.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_114.jpg  \n",
            "  inflating: dogs/dog_303.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_303.jpg  \n",
            "  inflating: dogs/dog_364.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_364.jpg  \n",
            "  inflating: dogs/dog_563.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_563.jpg  \n",
            "  inflating: dogs/dog_211.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_211.jpg  \n",
            "  inflating: dogs/dog_173.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_173.jpg  \n",
            "  inflating: dogs/dog_415.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_415.jpg  \n",
            "  inflating: dogs/dog_398.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_398.jpg  \n",
            "  inflating: dogs/dog_159.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_159.jpg  \n",
            "  inflating: dogs/dog_213.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_213.jpg  \n",
            "  inflating: dogs/dog_377.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_377.jpg  \n",
            "  inflating: dogs/dog_177.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_177.jpg  \n",
            "  inflating: dogs/dog_229.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_229.jpg  \n",
            "  inflating: dogs/dog_360.jpg        \n",
            "  inflating: __MACOSX/dogs/._dog_360.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**"
      ],
      "metadata": {
        "id": "LDsugRhAxjh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a train and test set (train-test ratio should be 80:20%)."
      ],
      "metadata": {
        "id": "ml13FRJHxwAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "cats_dir = \"/content/cats\"\n",
        "dogs_dir = \"/content/dogs\"\n",
        "\n",
        "#Create Train and Test Directories\n",
        "train_dir = \"train\"\n",
        "test_dir = \"test\"\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Function to split images into train and test\n",
        "def split_images(src_dir, class_label, train_dest, test_dest, train_ratio=0.8):\n",
        "    \"\"\"Splits images from a source folder into train and test sets.\"\"\"\n",
        "    all_images = [f for f in os.listdir(src_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    random.shuffle(all_images)\n",
        "\n",
        "    # Compute split index (80% train, 20% test)\n",
        "    split_index = int(train_ratio * len(all_images))\n",
        "    train_images = all_images[:split_index]\n",
        "    test_images = all_images[split_index:]\n",
        "\n",
        "    # Copy images to respective directories\n",
        "    for image_name in train_images:\n",
        "        src_path = os.path.join(src_dir, image_name)\n",
        "        new_filename = f\"{class_label}_{image_name}\"\n",
        "        dest_path = os.path.join(train_dest, new_filename)\n",
        "        shutil.copy(src_path, dest_path)\n",
        "\n",
        "    for image_name in test_images:\n",
        "        src_path = os.path.join(src_dir, image_name)\n",
        "        new_filename = f\"{class_label}_{image_name}\"\n",
        "        dest_path = os.path.join(test_dest, new_filename)\n",
        "        shutil.copy(src_path, dest_path)\n",
        "\n",
        "    print(f\"{class_label.capitalize()} - Train: {len(train_images)}, Test: {len(test_images)}\")\n",
        "\n",
        "\n",
        "split_images(cats_dir, \"cat\", train_dir, test_dir)\n",
        "split_images(dogs_dir, \"dog\", train_dir, test_dir)\n",
        "\n",
        "# Final Stats\n",
        "print(f\"Total Training Images: {len(os.listdir(train_dir))}\")\n",
        "print(f\"Total Testing Images: {len(os.listdir(test_dir))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNJzXEGml-7s",
        "outputId": "34594463-df75-40ec-d753-37bcda3feec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat - Train: 56, Test: 14\n",
            "Dog - Train: 56, Test: 14\n",
            "Total Training Images: 112\n",
            "Total Testing Images: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Custom Function using Augly, which will perform multiple random data augmentations according to input. (At least 10 data augmentation needs to be added like rotate, cropping, blur …)"
      ],
      "metadata": {
        "id": "mZDhGusfxxn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
        "import augly.image as imaugs\n",
        "\n",
        "def aug_rotate(image: Image.Image) -> Image.Image:\n",
        "    # Rotate the image by a small angle (-15° to +15°)\n",
        "    angle = random.uniform(-15, 15)\n",
        "    return imaugs.rotate(image, degrees=angle)\n",
        "\n",
        "def aug_crop(image: Image.Image) -> Image.Image:\n",
        "    # Crop 80-95% of the image and resize back to original\n",
        "    width, height = image.size\n",
        "    crop_ratio = random.uniform(0.05, 0.2)\n",
        "    left = int(width * crop_ratio)\n",
        "    top = int(height * crop_ratio)\n",
        "    right = int(width * (1 - crop_ratio))\n",
        "    bottom = int(height * (1 - crop_ratio))\n",
        "    cropped_image = image.crop((left, top, right, bottom))\n",
        "    return cropped_image.resize((width, height), Image.Resampling.LANCZOS)\n",
        "\n",
        "def aug_blur(image: Image.Image) -> Image.Image:\n",
        "    # Apply slight Gaussian blur (radius 0.5-1.5)\n",
        "    return image.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 1.5)))\n",
        "\n",
        "def aug_adjust_contrast(image: Image.Image) -> Image.Image:\n",
        "    # Adjust contrast slightly (0.9x to 1.1x).\n",
        "    factor = random.uniform(0.9, 1.1)\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    return enhancer.enhance(factor)\n",
        "\n",
        "def aug_horizontal_flip(image: Image.Image) -> Image.Image:\n",
        "    #Randomly flip the image horizontally\n",
        "    return imaugs.hflip(image) if random.random() > 0.5 else image\n",
        "\n",
        "def aug_jpeg_compression(image: Image.Image) -> Image.Image:\n",
        "    #Apply slight JPEG compression\n",
        "    return imaugs.encoding_quality(image, quality=random.randint(60, 100))\n",
        "\n",
        "def aug_sharpen(image: Image.Image) -> Image.Image:\n",
        "    #Apply sharpening to enhance edges\n",
        "    return image.filter(ImageFilter.SHARPEN)\n",
        "\n",
        "def aug_invert_colors(image: Image.Image) -> Image.Image:\n",
        "    # Invert image colors for variation\n",
        "    return ImageOps.invert(image)\n",
        "\n",
        "def aug_brightness(image: Image.Image) -> Image.Image:\n",
        "    #Adjust brightness slightly (0.9x to 1.1x)\n",
        "    factor = random.uniform(0.9, 1.1)\n",
        "    enhancer = ImageEnhance.Brightness(image)\n",
        "    return enhancer.enhance(factor)\n",
        "\n",
        "def aug_saturation(image: Image.Image) -> Image.Image:\n",
        "    #Adjust saturation slightly (0.9x to 1.1x).\n",
        "    factor = random.uniform(0.9, 1.1)\n",
        "    enhancer = ImageEnhance.Color(image)\n",
        "    return enhancer.enhance(factor)\n",
        "\n",
        "def apply_random_augmentations(image: Image.Image, chain_length: int = 2) -> Image.Image:\n",
        "    augmentation_functions = [\n",
        "        aug_rotate,\n",
        "        aug_crop,\n",
        "        aug_blur,\n",
        "        aug_adjust_contrast,\n",
        "        aug_horizontal_flip,\n",
        "        aug_jpeg_compression,\n",
        "        aug_sharpen,\n",
        "        aug_invert_colors,\n",
        "        aug_brightness,\n",
        "        aug_saturation\n",
        "    ]\n",
        "    chosen_funcs = random.sample(augmentation_functions, chain_length)\n",
        "    augmented = image\n",
        "    for func in chosen_funcs:\n",
        "        augmented = func(augmented)\n",
        "    return augmented"
      ],
      "metadata": {
        "id": "CRcGfPHBmfmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform data augmentation using the above function, only on the train set. (The number of augmented images should be twice the train set, and images should be augmented thrice example: cropped → rotate→Blur) (Second augmentation should be different )"
      ],
      "metadata": {
        "id": "6uUXS8EKx0al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "train_dir = \"train\"\n",
        "augmented_dir = \"train_aug\"\n",
        "\n",
        "if not os.path.exists(augmented_dir):\n",
        "    os.makedirs(augmented_dir)\n",
        "\n",
        "\n",
        "train_image_paths = glob.glob(os.path.join(train_dir, \"*.*\"))\n",
        "original_train_count = len(train_image_paths)\n",
        "augmented_count = 0\n",
        "counter = 1  # For unique filenames.\n",
        "\n",
        "for img_path in train_image_paths:\n",
        "    try:\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening {img_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "    base_name, ext = os.path.splitext(os.path.basename(img_path))\n",
        "\n",
        "    # Generate two augmented versions (each using a chain of 3 augmentations).\n",
        "    aug1 = apply_random_augmentations(image, chain_length=3)\n",
        "    aug2 = apply_random_augmentations(image, chain_length=3)\n",
        "\n",
        "    # Ensure the two augmentations are different.\n",
        "    while aug2.tobytes() == aug1.tobytes():\n",
        "        aug2 = apply_random_augmentations(image, chain_length=3)\n",
        "\n",
        "    # Save augmented images in the separate folder with unique filenames.\n",
        "    aug1_filename = os.path.join(augmented_dir, f\"{base_name}_aug1_{counter}{ext}\")\n",
        "    aug2_filename = os.path.join(augmented_dir, f\"{base_name}_aug2_{counter}{ext}\")\n",
        "    aug1.save(aug1_filename)\n",
        "    aug2.save(aug2_filename)\n",
        "\n",
        "    augmented_count += 2\n",
        "    counter += 1\n"
      ],
      "metadata": {
        "id": "ND38yIX4smLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the statistics of the newly created dataset. (Old dataset count and new dataset count)"
      ],
      "metadata": {
        "id": "uMLxP8lpx_Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Count original images from the original folder.\n",
        "old_count = len(glob.glob(os.path.join(train_dir, \"*.*\")))\n",
        "\n",
        "# Count augmented images from the augmented folder.\n",
        "aug_count = len(glob.glob(os.path.join(augmented_dir, \"*.*\")))\n",
        "\n",
        "# The new dataset count is the sum of originals and augmented images.\n",
        "new_count = old_count + aug_count\n",
        "\n",
        "print(\"Old dataset count (original images):\", old_count)\n",
        "print(\"Augmented image count:\", aug_count)\n",
        "print(\"New dataset count (original + augmented images):\", new_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PViqCTmxzJnF",
        "outputId": "10f5430c-6bb2-421a-9e51-ec64332a1bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old dataset count (original images): 112\n",
            "Augmented image count: 224\n",
            "New dataset count (original + augmented images): 336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"/content/train\"\n",
        "train_aug_dir = \"/content/train_aug\"\n",
        "test_dir = \"/content/test\"\n",
        "\n",
        "# Function to count the number of cat and dog images in a dataset directory\n",
        "def count_images(directory):\n",
        "\n",
        "    cat_count = 0\n",
        "    dog_count = 0\n",
        "\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.lower().startswith(\"cat_\"):\n",
        "            cat_count += 1\n",
        "        elif filename.lower().startswith(\"dog_\"):\n",
        "            dog_count += 1\n",
        "\n",
        "    return cat_count, dog_count\n",
        "\n",
        "# Get counts for each dataset\n",
        "train_cats, train_dogs = count_images(train_dir)\n",
        "aug_train_cats, aug_train_dogs = count_images(train_aug_dir)\n",
        "test_cats, test_dogs = count_images(test_dir)\n",
        "\n",
        "# Prepare data for visualization\n",
        "dataset_labels = [\"Train Set\", \"Augmented Train Set\", \"Test Set\"]\n",
        "cat_counts = [train_cats, aug_train_cats, test_cats]\n",
        "dog_counts = [train_dogs, aug_train_dogs, test_dogs]\n",
        "x = np.arange(len(dataset_labels))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot bars for Cats and Dogs\n",
        "ax.bar(x - bar_width/2, cat_counts, bar_width, label=\"Cats\", color=\"blue\")\n",
        "ax.bar(x + bar_width/2, dog_counts, bar_width, label=\"Dogs\", color=\"orange\")\n",
        "\n",
        "\n",
        "ax.set_title(\"Number of Cat & Dog Images in Each Dataset\", fontsize=14)\n",
        "ax.set_xlabel(\"Dataset\", fontsize=12)\n",
        "ax.set_ylabel(\"Image Count\", fontsize=12)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(dataset_labels)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "Kon_hbIBbLVj",
        "outputId": "cea586c6-ed49-440a-b4ef-d71d95c0a19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2"
      ],
      "metadata": {
        "id": "KKk6UPxLbuTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch torchvision scikit-learn matplotlib\n"
      ],
      "metadata": {
        "id": "zPyLydPA4QA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ea99c99c-b182-4f6f-b24d-e4bfa2ab6828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import os\n"
      ],
      "metadata": {
        "id": "r8_vYv2scKu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose (microsoft/resnet-50)model from the hugging face and initialize its new weights."
      ],
      "metadata": {
        "id": "a-Rg_Vhryq7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet-50 model from Hugging Face\n",
        "model_name = \"microsoft/resnet-50\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\", num_labels=2, ignore_mismatched_sizes=True).to(device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "e4a60640ee7d430eb88a0ac111970263",
            "955c919011924c8ca3f4173f700864ec",
            "ab53d7138f0c442398c5f28844e8af45",
            "e0e630cbfa6c4d1a96af82c394a79371",
            "f7900d740a8747fabbc8e01bcd995699",
            "5941c1fccbb349a987c645b7a04a28ae",
            "e39f563e3d7f4224a0a871277dd2ed96",
            "aa8eb12cf7d14b589acebb9f940b59b8",
            "70f6455952dc4e5697c38feaad3ccb5f",
            "35ae5079260d4b0d8236b3f8d9550702",
            "9604a3d8c18d439597b34eab2cd571d7",
            "d631d82317c248028ba3e65c56812626",
            "f1df7178712e4b169fa6cd16d9425c0e",
            "a7d071fa429148209bedfcc369100f8d",
            "6b3d845db5984ae9813ebdb0444ea998",
            "fa064b7e6128425ab4398a07c0ffa4e5",
            "808b60b052a34380ac9f88039b950a81",
            "0da3a921e3b54d94826b7e55a78adde1",
            "0f3205ea914a451bbbf98e310c58c77c",
            "752b0bb9d20f4cf0a2ef2d57cff650a2",
            "4a71957779c84c78ae9ee0bad1f61da9",
            "46c0887919bd4f5b8b28a2df09ee2c52"
          ]
        },
        "collapsed": true,
        "id": "0CkIx0XPcOqK",
        "outputId": "f21a6917-0020-4934-df98-ab9d476ccfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4a60640ee7d430eb88a0ac111970263"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d631d82317c248028ba3e65c56812626"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
            "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Architecture diagram**"
      ],
      "metadata": {
        "id": "jx8IVeXu0sVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Architecture\n",
        "for name, module in model.named_children():\n",
        "    print(f\"{name}: {module}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYhVe4fzqCd7",
        "outputId": "9f838c3a-c762-4452-bb34-3a7c51af0412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet: ResNetModel(\n",
            "  (embedder): ResNetEmbeddings(\n",
            "    (embedder): ResNetConvLayer(\n",
            "      (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (encoder): ResNetEncoder(\n",
            "    (stages): ModuleList(\n",
            "      (0): ResNetStage(\n",
            "        (layers): Sequential(\n",
            "          (0): ResNetBottleNeckLayer(\n",
            "            (shortcut): ResNetShortCut(\n",
            "              (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (1): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (2): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): ResNetStage(\n",
            "        (layers): Sequential(\n",
            "          (0): ResNetBottleNeckLayer(\n",
            "            (shortcut): ResNetShortCut(\n",
            "              (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (1): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (2): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (3): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): ResNetStage(\n",
            "        (layers): Sequential(\n",
            "          (0): ResNetBottleNeckLayer(\n",
            "            (shortcut): ResNetShortCut(\n",
            "              (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (1): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (2): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (3): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (4): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (5): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): ResNetStage(\n",
            "        (layers): Sequential(\n",
            "          (0): ResNetBottleNeckLayer(\n",
            "            (shortcut): ResNetShortCut(\n",
            "              (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (1): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "          (2): ResNetBottleNeckLayer(\n",
            "            (shortcut): Identity()\n",
            "            (layer): Sequential(\n",
            "              (0): ResNetConvLayer(\n",
            "                (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (1): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): ReLU()\n",
            "              )\n",
            "              (2): ResNetConvLayer(\n",
            "                (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (activation): Identity()\n",
            "              )\n",
            "            )\n",
            "            (activation): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            ")\n",
            "classifier: Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet-50's feature extractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "\n",
        "# Define transformations (ResNet-50 input format: 224x224)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "0fb682fcd73b42c8b52a501494799c41",
            "6828e3b1945e45beb5a25202ae48b77f",
            "ee162c6cb23642c281cae8dea30a9af9",
            "55f1dd928854412189a30210c01aa6f2",
            "372d6b7d38834305bc1337c3e7c81742",
            "47c86c15432d4715a9d9a029a8eef42c",
            "11376694ce80412b8e3ccdac17e81bcf",
            "16a151fb370b49688972791ed3e24afd",
            "88f84c16b42447ed9ea00efbd9a762ee",
            "af71894449454de89bb0e2c3bba27ddf",
            "3551398974f24c06953616cb292a0192"
          ]
        },
        "collapsed": true,
        "id": "F-MTB8F4cWGB",
        "outputId": "4d3c3ff0-0e2c-4fb3-ed9a-c0ee5873e235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fb682fcd73b42c8b52a501494799c41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/convnext/feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making subdirectories in the train directory to make training easy\n"
      ],
      "metadata": {
        "id": "fAEwSRF31P9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"/content/train\"\n",
        "train_aug_dir = \"/content/train_aug\"\n",
        "test_dir = \"/content/test\"\n",
        "\n",
        "# Create class subdirectories if they don't exist\n",
        "for class_name in [\"cat\", \"dog\"]:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(train_aug_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "# Move images into respective class folders\n",
        "def move_images_to_class_folders(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.startswith(\"cat_\"):\n",
        "            shutil.move(os.path.join(directory, filename), os.path.join(directory, \"cat\", filename))\n",
        "        elif filename.startswith(\"dog_\"):\n",
        "            shutil.move(os.path.join(directory, filename), os.path.join(directory, \"dog\", filename))\n",
        "\n",
        "# Organize images in train, train_aug, and test sets\n",
        "move_images_to_class_folders(train_dir)\n",
        "move_images_to_class_folders(train_aug_dir)\n",
        "move_images_to_class_folders(test_dir)\n",
        "\n",
        "print(\"Dataset structure fixed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0MMKgEsdBfI",
        "outputId": "d72803a8-4a53-48e0-e829-25dc07d17e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset structure fixed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to datasets\n",
        "train_dir = \"/content/train\"\n",
        "train_aug_dir = \"/content/train_aug\"\n",
        "test_dir = \"/content/test\"\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "train_aug_dataset = datasets.ImageFolder(root=train_aug_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "train_aug_loader = DataLoader(train_aug_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "ftxWuQ0Gcc7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the training parameters"
      ],
      "metadata": {
        "id": "K-f1Oxon3CVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = \"AdamW\"\n",
        "LOSS_FN = \"CrossEntropyLoss\"\n",
        "\n",
        "print(\"Training Parameters:\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Optimizer: {OPTIMIZER}\")\n",
        "print(f\"Loss Function: {LOSS_FN}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJG4ZFjmoq6j",
        "outputId": "035e4bee-cf92-4df6-e2e1-6142430f67df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Parameters:\n",
            "Batch Size: 32\n",
            "Epochs: 10\n",
            "Learning Rate: 2e-05\n",
            "Optimizer: AdamW\n",
            "Loss Function: CrossEntropyLoss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model(created in the above point) on a downloaded dataset, without augmentation."
      ],
      "metadata": {
        "id": "Cfiv58puygOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, epochs=10, learning_rate=1e-4):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-Ji4YPuvdFue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training on Original Dataset (No Augmentation)...\")\n",
        "model_original = train_model(model, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZwcxryGdRLQ",
        "outputId": "1a3e8c8f-a4e7-408b-883b-c5b8112a9f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Original Dataset (No Augmentation)...\n",
            "Epoch 1/10, Loss: 0.6843\n",
            "Epoch 2/10, Loss: 0.6577\n",
            "Epoch 3/10, Loss: 0.6317\n",
            "Epoch 4/10, Loss: 0.6068\n",
            "Epoch 5/10, Loss: 0.5885\n",
            "Epoch 6/10, Loss: 0.5678\n",
            "Epoch 7/10, Loss: 0.5404\n",
            "Epoch 8/10, Loss: 0.5044\n",
            "Epoch 9/10, Loss: 0.4905\n",
            "Epoch 10/10, Loss: 0.4597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model(created in the first point) on a downloaded dataset with augmentation."
      ],
      "metadata": {
        "id": "lqU1yweDydjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load pretrained ResNet-50, ignoring classifier mismatched size\n",
        "model_aug = AutoModelForImageClassification.from_pretrained(\n",
        "    \"microsoft/resnet-50\",\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(device)\n",
        "\n",
        "# Reinitialize the classifier weights properly\n",
        "nn.init.xavier_uniform_(model_aug.classifier[1].weight)\n",
        "nn.init.zeros_(model_aug.classifier[1].bias)\n",
        "\n",
        "print(\"Model initialized correctly. Training on Augmented Dataset...\")\n",
        "model_aug = train_model(model_aug, train_aug_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RYZBmyndZzT",
        "outputId": "920f385f-d688-4194-bb29-f71cabd3a13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
            "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized correctly. Training on Augmented Dataset...\n",
            "Epoch 1/10, Loss: 0.6896\n",
            "Epoch 2/10, Loss: 0.6067\n",
            "Epoch 3/10, Loss: 0.5384\n",
            "Epoch 4/10, Loss: 0.4866\n",
            "Epoch 5/10, Loss: 0.4428\n",
            "Epoch 6/10, Loss: 0.3904\n",
            "Epoch 7/10, Loss: 0.3402\n",
            "Epoch 8/10, Loss: 0.2927\n",
            "Epoch 9/10, Loss: 0.2522\n",
            "Epoch 10/10, Loss: 0.2146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the precision, recall, F1 score, and accuracy of both the models on the test set.\n"
      ],
      "metadata": {
        "id": "uiA3Sx_KyZYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images).logits\n",
        "            predictions = torch.argmax(outputs, dim=1)  # Get class with highest probability\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())  # Collect true labels\n",
        "            y_pred.extend(predictions.cpu().numpy())  # Collect predicted labels\n",
        "\n",
        "    return y_true, y_pred\n"
      ],
      "metadata": {
        "id": "7F2Z6NwKdj0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model trained on original dataset\n",
        "y_true_orig, y_pred_orig = evaluate_model(model_original, test_loader)\n",
        "\n",
        "# Evaluate model trained on augmented dataset\n",
        "y_true_aug, y_pred_aug = evaluate_model(model_aug, test_loader)\n"
      ],
      "metadata": {
        "id": "EYB_iZ7Wdonc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Compute TP, TN, FP, FN\n",
        "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
        "    # True Positives (Dog correctly predicted)\n",
        "    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
        "    # True Negatives (Cat correctly predicted)\n",
        "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
        "    # False Positives (Predicted Dog but it was Cat)\n",
        "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
        "    # False Negatives (Predicted Cat but it was Dog)\n",
        "\n",
        "    # Calculate Precision, Recall, F1-score, Accuracy\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "    return precision, recall, f1_score, accuracy\n"
      ],
      "metadata": {
        "id": "hXDXO95Kf3VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics for original model (without augmentation)\n",
        "precision_orig, recall_orig, f1_orig, acc_orig = calculate_metrics(y_true_orig, y_pred_orig)\n",
        "\n",
        "# Compute metrics for augmented model\n",
        "precision_aug, recall_aug, f1_aug, acc_aug = calculate_metrics(y_true_aug, y_pred_aug)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nWithout Augmentation - Accuracy: {acc_orig:.4f}, Precision: {precision_orig:.4f}, Recall: {recall_orig:.4f}, F1-score: {f1_orig:.4f}\")\n",
        "print(f\"\\nWith Augmentation - Accuracy: {acc_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-score: {f1_aug:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrB6FJrZf8aG",
        "outputId": "404d59be-13c5-4c21-ad65-db87ba88f763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Without Augmentation - Accuracy: 0.8929, Precision: 0.9231, Recall: 0.8571, F1-score: 0.8889\n",
            "\n",
            "With Augmentation - Accuracy: 0.9643, Precision: 0.9333, Recall: 1.0000, F1-score: 0.9655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model performs much better after using augmented data, with higher accuracy and recall.<br>Data augmentation likely helped the model avoid overfitting to the training data, leading to better performance on unseen data.<br>Augmentation introduced more variability into the training data, enabling the model to learn more strong features.<br>Augmentation may have helped address class imbalance by generating more diverse samples for underrepresented classes, leading to more balanced and fair predictions across all classes."
      ],
      "metadata": {
        "id": "_hXfHrcE35cE"
      }
    }
  ]
}